{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae240cfa-9330-4944-91d7-9f447bd5b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Function to draw an image/array\n",
    "def drawDigit(data : np.ndarray) ->None:\n",
    "    plt.imshow(data, cmap='gray')\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2db8b90",
   "metadata": {},
   "source": [
    "### Import and split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a99ab17d-c80e-4c2f-a797-bd1f241944e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 16, 15), (2000, 10))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open Data into (2000,16,15) np.array\n",
    "Data_X = np.empty([2000, 16, 15])\n",
    "Data_Y = np.empty([2000,])\n",
    "with open(\"nestor files/mfeat-pix.txt\", 'r') as file:\n",
    "    file = file.readlines()\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        k = 0\n",
    "        l = 0\n",
    "        for character in line:\n",
    "            if character.isdigit():\n",
    "                Data_X[i][k][l] = float(int(character)/6.0)#read digit and normalize data while reading it in!\n",
    "                l+=1\n",
    "                if l == 15:\n",
    "                    l = 0\n",
    "                    k+=1\n",
    "        Data_Y[i] = int(i / 200)\n",
    "        i+=1\n",
    "Data_Y = tf.keras.utils.to_categorical(Data_Y)\n",
    "Data_X.shape, Data_Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdc36aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_X.min(), Data_X.max(), Data_Y.min(), Data_Y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ad5290-2798-496a-a0da-dd7c2505a1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last entry should be a 9!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Example to check it works\n",
    "drawDigit(Data_X[-1])\n",
    "print(\"The last entry should be a 9!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1087c344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be a [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Split DataSet into Testing and Training Data\n",
    "TRAIN_X,TEST_X, TRAIN_Y, TEST_Y = None, None, None, None\n",
    "\n",
    "EASY_SPLIT = False\n",
    "if EASY_SPLIT:\n",
    "    TRAIN_X,TEST_X, TRAIN_Y, TEST_Y = train_test_split(Data_X, Data_Y, test_size=0.2)\n",
    "else:\n",
    "    TRAIN_X = np.empty([1000, 16, 15])\n",
    "    TRAIN_Y = np.empty([1000, 10])\n",
    "    TEST_X = np.empty([1000, 16, 15])\n",
    "    TEST_Y = np.empty([1000, 10])\n",
    "\n",
    "    train_idx, test_idx, helper_idx = 0, 0, 0\n",
    "    assign_to_train = True\n",
    "    for sample_point in zip(Data_X, Data_Y):\n",
    "        if assign_to_train:\n",
    "            TRAIN_X[train_idx] = sample_point[0]\n",
    "            TRAIN_Y[train_idx] = sample_point[1]\n",
    "            train_idx += 1\n",
    "        elif not assign_to_train:\n",
    "            TEST_X[test_idx] = sample_point[0]\n",
    "            TEST_Y[test_idx] = sample_point[1]\n",
    "            test_idx += 1\n",
    "        helper_idx += 1\n",
    "        if helper_idx == 100:\n",
    "            assign_to_train = False\n",
    "        elif helper_idx == 200:\n",
    "            assign_to_train = True\n",
    "            helper_idx = 0\n",
    "\n",
    "\n",
    "print(f\"Should be a {TEST_Y[-1]}\")\n",
    "drawDigit(TEST_X[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04ba45d1",
   "metadata": {},
   "source": [
    "### K-Neighearest Neighbor Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9f2b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the labels\n",
    "labels = np.zeros(2000)\n",
    "\n",
    "# assign the labels (0-9) to the first 200 instances of each digit\n",
    "for i in range(10):\n",
    "    labels[i*200:(i+1)*200] = i\n",
    "\n",
    "# reshape the data to be 2D\n",
    "knn_data = Data_X.reshape(2000, 16 * 15)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(knn_data, labels, test_size=0.2, random_state=69)\n",
    "\n",
    "# first try k = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e56a8b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3928b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 43  0  0  0  1  0  0  0  0]\n",
      " [ 0  0 41  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 39  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 34  0  1  0  0  0]\n",
      " [ 0  0  0  0  0 41  0  0  0  0]\n",
      " [ 0  0  0  0  0  1 38  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 34  0  0]\n",
      " [ 2  0  0  0  0  0  0  0 44  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98        41\n",
      "         1.0       1.00      0.98      0.99        44\n",
      "         2.0       1.00      1.00      1.00        41\n",
      "         3.0       1.00      1.00      1.00        39\n",
      "         4.0       1.00      0.97      0.99        35\n",
      "         5.0       0.95      1.00      0.98        41\n",
      "         6.0       0.97      0.97      0.97        39\n",
      "         7.0       1.00      1.00      1.00        34\n",
      "         8.0       1.00      0.96      0.98        46\n",
      "         9.0       1.00      1.00      1.00        40\n",
      "\n",
      "    accuracy                           0.99       400\n",
      "   macro avg       0.99      0.99      0.99       400\n",
      "weighted avg       0.99      0.99      0.99       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Stuff\\Python\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f637545",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6b8a36e",
   "metadata": {},
   "source": [
    "Steps:<br>\n",
    "1. Preprocess (reshape, prepare input and create solution vectors)<br>\n",
    "2. Create architectures<br>\n",
    "3. Train each Architecture<br>\n",
    "4. Evaluate each Architecture<br>\n",
    "5. Compare<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03c9d107",
   "metadata": {},
   "source": [
    "#### 2 - Prepare Architectures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2af7291a",
   "metadata": {},
   "source": [
    "LeCunArchitecture:\n",
    "- Convolutional Layer: 6 features, 5x5 kernel\n",
    "- Pooling layer: average pooling, 2x2 kernel\n",
    "- Convolutional layer: 16 features, 5x5 kernel\n",
    "- Pooling layer: average pooling, 2x2 kernel\n",
    "- MLP layers: 2 flat layers\n",
    "- Output Layer\n",
    "\n",
    "Architecture parameters:\n",
    "- conv features layer 1+2: 6(original), 4, 8, 16?\n",
    "- conv layers kernel sizes: 3x3, 5x5 (higher might introduces problem due to input size)\n",
    "- pooling kernels both layers: keep  on 2x2\n",
    "- hideen layers: number of eurons, 16, 32?\n",
    "- of learning rates r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e592fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_architecture:\n",
    "    def __init__(self, c1_features : int = 6,#number of features in conv layer 1extracted\n",
    "                 c1_kernel : int = 3,\n",
    "                 c1_pooling : int = 2,\n",
    "                 c2_features : int = 16, #number of features in conv layer 2 extracted\n",
    "                 c2_kernel : int = 5,\n",
    "                 c2_pooling : int = 2,\n",
    "                 c_dropout_rate : float = 0.25, #rate of dropout after conv layers\n",
    "                 f_dropout_rate : float = 0.5,#rate of dropout after fc layers\n",
    "                 fc_layers : list = [],  #list containing integers which represents the number of neurons PER layer. \n",
    "                 pool_type :str = \"max\"\n",
    "                 ):\n",
    "        self.model = None\n",
    "        self.evaluation = None\n",
    "        self.history = None\n",
    "        try:\n",
    "            self.model = tf.keras.Sequential()\n",
    "            #First conv+sampling layers\n",
    "            self.model.add(tf.keras.layers.Conv2D(c1_features, kernel_size = c1_kernel, activation='relu', input_shape = (16,15,1)))\n",
    "            if pool_type == \"avg\":\n",
    "                self.model.add(tf.keras.layers.AveragePooling2D(pool_size = c1_pooling))\n",
    "            elif pool_type == \"max\":\n",
    "                self.model.add(tf.keras.layers.MaxPooling2D(pool_size = c1_pooling))\n",
    "            #Second conv+sampling layer\n",
    "            self.model.add(tf.keras.layers.Conv2D(c2_features, kernel_size = c2_kernel, activation='relu'))\n",
    "            if pool_type == \"avg\":\n",
    "                self.model.add(tf.keras.layers.AveragePooling2D(pool_size = c2_pooling))\n",
    "            elif pool_type == \"max\":\n",
    "                self.model.add(tf.keras.layers.MaxPooling2D(pool_size = c2_pooling))\n",
    "            #convert to flat layer\n",
    "            self.model.add(tf.keras.layers.Dropout(c_dropout_rate))\n",
    "            self.model.add(tf.keras.layers.Flatten())\n",
    "            #add hidden layers\n",
    "            for lay in fc_layers:\n",
    "                if type(lay)== int and lay > 0:\n",
    "                    self.model.add(tf.keras.layers.Dense(lay, activation='relu'))\n",
    "            #finalize with output layer\n",
    "            self.model.add(tf.keras.layers.Dropout(f_dropout_rate))\n",
    "            self.model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "        except:\n",
    "             self.model = None\n",
    "\n",
    "    def print_architecture(self):\n",
    "         if (type(self.model) == tf.keras.Sequential):\n",
    "            print(self.model.summary())\n",
    "    def compile_model(self, optimizer : tf.keras.optimizers = tf.keras.optimizers.RMSprop()):\n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=['mse', 'accuracy'])\n",
    "    def train_model(self, x, y, epochs, batch, callbacks):\n",
    "        self.history = self.model.fit(x=x, y=y, epochs=epochs, batch_size=batch, callbacks=callbacks)\n",
    "    def test_model(self, x, y):\n",
    "        self.evaluation = self.model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c109c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters. careful its gonna be ugly\n",
    "filters1 = (6, 12, 24)\n",
    "filters2 = (8, 16, 32, 64)\n",
    "pooling_types = (\"max\")\n",
    "pooling_sizes = (2)\n",
    "filter_sizes = (3,5)\n",
    "hiddenneurons = ([], [20], [10, 20], [20, 20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ec9fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of model architectures\n",
    "model_list = [cnn_architecture(), cnn_architecture(fc_layers=[20]), cnn_architecture(fc_layers=[10, 20]), cnn_architecture(fc_layers=[20, 20])]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62b26903",
   "metadata": {},
   "source": [
    "#### 3 Train Architectures\n",
    "- Full batch (because technically small dataset)? learning rate may be a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b2e158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set interessting callbacks\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='mse', patience=20)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "K = 5\n",
    "EPOCHS = range(15,30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6971ca7",
   "metadata": {},
   "source": [
    "Next we need hyperparameters for training including:\n",
    "- k: for the number of folds in k-fold cross validation (2-10?)\n",
    "- epochs (1-10?)\n",
    "- batch size (10, 20, 30... 100?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daf3d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling models\n",
    "for model in model_list:\n",
    "    model.compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c64bdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8478 - mse: 0.0415 - accuracy: 0.6670\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8759 - mse: 0.0425 - accuracy: 0.6620\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8235 - mse: 0.0407 - accuracy: 0.6690\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8833 - mse: 0.0438 - accuracy: 0.6390\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8546 - mse: 0.0413 - accuracy: 0.6590\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8376 - mse: 0.0407 - accuracy: 0.6780\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8689 - mse: 0.0427 - accuracy: 0.6510\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8104 - mse: 0.0401 - accuracy: 0.6820\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8198 - mse: 0.0405 - accuracy: 0.6800\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8433 - mse: 0.0415 - accuracy: 0.6710\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8484 - mse: 0.0415 - accuracy: 0.6570\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7909 - mse: 0.0394 - accuracy: 0.6860\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8155 - mse: 0.0406 - accuracy: 0.6690\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8100 - mse: 0.0403 - accuracy: 0.6700\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8413 - mse: 0.0412 - accuracy: 0.6740\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8083 - mse: 0.0399 - accuracy: 0.6890\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7958 - mse: 0.0390 - accuracy: 0.6880\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8385 - mse: 0.0411 - accuracy: 0.6730\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8558 - mse: 0.0426 - accuracy: 0.6460\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8303 - mse: 0.0415 - accuracy: 0.6470\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8037 - mse: 0.0395 - accuracy: 0.6880\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7745 - mse: 0.0392 - accuracy: 0.6960\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8274 - mse: 0.0406 - accuracy: 0.6690\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8411 - mse: 0.0424 - accuracy: 0.6640\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7836 - mse: 0.0391 - accuracy: 0.6900\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8626 - mse: 0.0424 - accuracy: 0.6550\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7985 - mse: 0.0394 - accuracy: 0.6710\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8364 - mse: 0.0426 - accuracy: 0.6590\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8107 - mse: 0.0406 - accuracy: 0.6860\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7990 - mse: 0.0397 - accuracy: 0.6720\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8178 - mse: 0.0416 - accuracy: 0.6750\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8320 - mse: 0.0409 - accuracy: 0.6810\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7588 - mse: 0.0377 - accuracy: 0.6910\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8321 - mse: 0.0411 - accuracy: 0.6680\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8333 - mse: 0.0427 - accuracy: 0.6500\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7904 - mse: 0.0381 - accuracy: 0.7070\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7864 - mse: 0.0399 - accuracy: 0.6840\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7997 - mse: 0.0403 - accuracy: 0.6700\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8391 - mse: 0.0420 - accuracy: 0.6490\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7573 - mse: 0.0386 - accuracy: 0.6850\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8269 - mse: 0.0414 - accuracy: 0.6710\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7917 - mse: 0.0396 - accuracy: 0.6840\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8091 - mse: 0.0401 - accuracy: 0.6860\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7751 - mse: 0.0389 - accuracy: 0.6890\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7548 - mse: 0.0378 - accuracy: 0.6950\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7852 - mse: 0.0395 - accuracy: 0.6830\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7962 - mse: 0.0394 - accuracy: 0.6720\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8030 - mse: 0.0406 - accuracy: 0.6760\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7352 - mse: 0.0372 - accuracy: 0.7070\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7673 - mse: 0.0382 - accuracy: 0.6980\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7426 - mse: 0.0374 - accuracy: 0.6890\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7644 - mse: 0.0379 - accuracy: 0.6950\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7563 - mse: 0.0381 - accuracy: 0.6900\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7723 - mse: 0.0388 - accuracy: 0.6900\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7571 - mse: 0.0381 - accuracy: 0.7090\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7980 - mse: 0.0397 - accuracy: 0.6770\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7628 - mse: 0.0380 - accuracy: 0.7030\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7715 - mse: 0.0389 - accuracy: 0.6910\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7927 - mse: 0.0399 - accuracy: 0.6810\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7559 - mse: 0.0382 - accuracy: 0.6880\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7988 - mse: 0.0404 - accuracy: 0.6650\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7452 - mse: 0.0376 - accuracy: 0.6920\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7818 - mse: 0.0397 - accuracy: 0.6750\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7870 - mse: 0.0398 - accuracy: 0.6850\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7708 - mse: 0.0384 - accuracy: 0.6990\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7866 - mse: 0.0388 - accuracy: 0.6750\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7502 - mse: 0.0378 - accuracy: 0.6990\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7353 - mse: 0.0377 - accuracy: 0.6880\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7648 - mse: 0.0394 - accuracy: 0.6910\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7025 - mse: 0.0340 - accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6998 - mse: 0.0338 - accuracy: 0.7610\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6108 - mse: 0.0309 - accuracy: 0.7730\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7145 - mse: 0.0347 - accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6908 - mse: 0.0345 - accuracy: 0.7410\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6549 - mse: 0.0324 - accuracy: 0.7760\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6661 - mse: 0.0330 - accuracy: 0.7610\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6498 - mse: 0.0325 - accuracy: 0.7640\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6838 - mse: 0.0337 - accuracy: 0.7660\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7035 - mse: 0.0350 - accuracy: 0.7350\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6948 - mse: 0.0343 - accuracy: 0.7540\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6814 - mse: 0.0340 - accuracy: 0.7440\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6348 - mse: 0.0318 - accuracy: 0.7680\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6053 - mse: 0.0300 - accuracy: 0.7790\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7000 - mse: 0.0343 - accuracy: 0.7630\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6539 - mse: 0.0325 - accuracy: 0.7580\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6452 - mse: 0.0325 - accuracy: 0.7610\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6228 - mse: 0.0309 - accuracy: 0.7750\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6601 - mse: 0.0331 - accuracy: 0.7590\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6654 - mse: 0.0324 - accuracy: 0.7620\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6757 - mse: 0.0331 - accuracy: 0.7530\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6566 - mse: 0.0318 - accuracy: 0.7670\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6100 - mse: 0.0307 - accuracy: 0.7840\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6667 - mse: 0.0325 - accuracy: 0.7670\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6195 - mse: 0.0308 - accuracy: 0.7850\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6237 - mse: 0.0317 - accuracy: 0.7660\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6365 - mse: 0.0315 - accuracy: 0.7680\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6301 - mse: 0.0318 - accuracy: 0.7660\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6206 - mse: 0.0311 - accuracy: 0.7800\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6019 - mse: 0.0301 - accuracy: 0.7770\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6159 - mse: 0.0299 - accuracy: 0.7830\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6348 - mse: 0.0318 - accuracy: 0.7730\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6270 - mse: 0.0313 - accuracy: 0.7780\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6499 - mse: 0.0328 - accuracy: 0.7530\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6485 - mse: 0.0326 - accuracy: 0.7580\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6063 - mse: 0.0308 - accuracy: 0.7840\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6068 - mse: 0.0300 - accuracy: 0.7820\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5700 - mse: 0.0289 - accuracy: 0.8030\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5846 - mse: 0.0296 - accuracy: 0.7760\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6322 - mse: 0.0315 - accuracy: 0.7720\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6114 - mse: 0.0310 - accuracy: 0.7660\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5870 - mse: 0.0298 - accuracy: 0.7820\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5686 - mse: 0.0283 - accuracy: 0.7900\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5837 - mse: 0.0304 - accuracy: 0.7820\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5992 - mse: 0.0297 - accuracy: 0.7880\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5772 - mse: 0.0291 - accuracy: 0.7830\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5602 - mse: 0.0286 - accuracy: 0.7960\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5588 - mse: 0.0285 - accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5513 - mse: 0.0274 - accuracy: 0.8030\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5942 - mse: 0.0301 - accuracy: 0.7810\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5372 - mse: 0.0272 - accuracy: 0.8130\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5863 - mse: 0.0292 - accuracy: 0.7850\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5537 - mse: 0.0277 - accuracy: 0.8010\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5747 - mse: 0.0287 - accuracy: 0.7960\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5750 - mse: 0.0295 - accuracy: 0.7940\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5799 - mse: 0.0282 - accuracy: 0.8050\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5648 - mse: 0.0276 - accuracy: 0.7990\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5642 - mse: 0.0281 - accuracy: 0.7970\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6107 - mse: 0.0306 - accuracy: 0.7930\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5561 - mse: 0.0276 - accuracy: 0.8130\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5420 - mse: 0.0273 - accuracy: 0.8040\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5446 - mse: 0.0275 - accuracy: 0.8030\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5458 - mse: 0.0277 - accuracy: 0.8000\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5088 - mse: 0.0254 - accuracy: 0.8220\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5610 - mse: 0.0282 - accuracy: 0.7940\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5521 - mse: 0.0280 - accuracy: 0.7860\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5206 - mse: 0.0267 - accuracy: 0.8030\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5956 - mse: 0.0296 - accuracy: 0.7790\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5308 - mse: 0.0272 - accuracy: 0.8010\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5378 - mse: 0.0276 - accuracy: 0.8040\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5470 - mse: 0.0279 - accuracy: 0.8170\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5426 - mse: 0.0278 - accuracy: 0.7890\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5223 - mse: 0.0265 - accuracy: 0.8100\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5489 - mse: 0.0274 - accuracy: 0.8060\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5524 - mse: 0.0282 - accuracy: 0.7990\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5450 - mse: 0.0279 - accuracy: 0.7940\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5233 - mse: 0.0261 - accuracy: 0.8190\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5293 - mse: 0.0264 - accuracy: 0.8190\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5915 - mse: 0.0300 - accuracy: 0.7820\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5092 - mse: 0.0262 - accuracy: 0.8200\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5207 - mse: 0.0263 - accuracy: 0.8070\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4880 - mse: 0.0255 - accuracy: 0.8260\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5181 - mse: 0.0261 - accuracy: 0.8130\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5113 - mse: 0.0261 - accuracy: 0.8180\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9472 - mse: 0.0465 - accuracy: 0.6400\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9384 - mse: 0.0456 - accuracy: 0.6570\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9079 - mse: 0.0445 - accuracy: 0.6720\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9254 - mse: 0.0453 - accuracy: 0.6550\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8948 - mse: 0.0438 - accuracy: 0.6790\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8850 - mse: 0.0436 - accuracy: 0.6720\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8923 - mse: 0.0438 - accuracy: 0.6670\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8986 - mse: 0.0440 - accuracy: 0.6600\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9108 - mse: 0.0450 - accuracy: 0.6480\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8753 - mse: 0.0435 - accuracy: 0.6780\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9095 - mse: 0.0451 - accuracy: 0.6570\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8729 - mse: 0.0432 - accuracy: 0.6790\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9161 - mse: 0.0453 - accuracy: 0.6430\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8574 - mse: 0.0408 - accuracy: 0.6850\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9025 - mse: 0.0442 - accuracy: 0.6560\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9072 - mse: 0.0446 - accuracy: 0.6620\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8805 - mse: 0.0429 - accuracy: 0.6760\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8645 - mse: 0.0421 - accuracy: 0.6800\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8876 - mse: 0.0437 - accuracy: 0.6710\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9086 - mse: 0.0442 - accuracy: 0.6730\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8437 - mse: 0.0414 - accuracy: 0.6820\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8569 - mse: 0.0423 - accuracy: 0.6800\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8616 - mse: 0.0425 - accuracy: 0.6860\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8831 - mse: 0.0437 - accuracy: 0.6670\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8174 - mse: 0.0413 - accuracy: 0.6750\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8513 - mse: 0.0418 - accuracy: 0.6920\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8579 - mse: 0.0424 - accuracy: 0.6790\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8708 - mse: 0.0426 - accuracy: 0.6730\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8284 - mse: 0.0414 - accuracy: 0.6730\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8618 - mse: 0.0420 - accuracy: 0.6650\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8048 - mse: 0.0400 - accuracy: 0.6980\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8684 - mse: 0.0428 - accuracy: 0.6810\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8198 - mse: 0.0416 - accuracy: 0.6840\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8195 - mse: 0.0406 - accuracy: 0.6790\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8078 - mse: 0.0399 - accuracy: 0.6990\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7911 - mse: 0.0396 - accuracy: 0.6950\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8214 - mse: 0.0399 - accuracy: 0.7030\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9068 - mse: 0.0450 - accuracy: 0.6490\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8212 - mse: 0.0393 - accuracy: 0.7080\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8250 - mse: 0.0410 - accuracy: 0.6850\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7691 - mse: 0.0389 - accuracy: 0.7020\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7996 - mse: 0.0404 - accuracy: 0.6940\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7875 - mse: 0.0381 - accuracy: 0.7270\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8420 - mse: 0.0407 - accuracy: 0.6980\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7938 - mse: 0.0399 - accuracy: 0.6930\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7997 - mse: 0.0400 - accuracy: 0.6900\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7823 - mse: 0.0389 - accuracy: 0.7140\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8166 - mse: 0.0399 - accuracy: 0.7040\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7718 - mse: 0.0383 - accuracy: 0.7050\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8119 - mse: 0.0402 - accuracy: 0.6860\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7790 - mse: 0.0392 - accuracy: 0.7060\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7594 - mse: 0.0382 - accuracy: 0.7130\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7887 - mse: 0.0390 - accuracy: 0.7120\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8050 - mse: 0.0393 - accuracy: 0.7120\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7659 - mse: 0.0386 - accuracy: 0.6980\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7000 - mse: 0.0361 - accuracy: 0.7290\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8282 - mse: 0.0396 - accuracy: 0.7010\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7733 - mse: 0.0384 - accuracy: 0.7190\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8279 - mse: 0.0405 - accuracy: 0.7000\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8109 - mse: 0.0407 - accuracy: 0.6910\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7805 - mse: 0.0386 - accuracy: 0.7080\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7927 - mse: 0.0384 - accuracy: 0.7140\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7742 - mse: 0.0387 - accuracy: 0.7040\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7539 - mse: 0.0374 - accuracy: 0.7100\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7654 - mse: 0.0382 - accuracy: 0.7070\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7960 - mse: 0.0395 - accuracy: 0.6900\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7843 - mse: 0.0395 - accuracy: 0.6940\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7941 - mse: 0.0386 - accuracy: 0.7150\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7931 - mse: 0.0401 - accuracy: 0.6960\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7227 - mse: 0.0356 - accuracy: 0.7390\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8249 - mse: 0.0404 - accuracy: 0.6940\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7670 - mse: 0.0377 - accuracy: 0.7090\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7327 - mse: 0.0376 - accuracy: 0.7200\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7488 - mse: 0.0379 - accuracy: 0.7070\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7694 - mse: 0.0384 - accuracy: 0.7020\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7439 - mse: 0.0368 - accuracy: 0.7270\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7944 - mse: 0.0394 - accuracy: 0.7120\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8084 - mse: 0.0394 - accuracy: 0.7000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7304 - mse: 0.0369 - accuracy: 0.7190\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7321 - mse: 0.0367 - accuracy: 0.7140\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7706 - mse: 0.0386 - accuracy: 0.7030\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8108 - mse: 0.0397 - accuracy: 0.7060\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7850 - mse: 0.0391 - accuracy: 0.6970\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7161 - mse: 0.0365 - accuracy: 0.7320\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7273 - mse: 0.0365 - accuracy: 0.7360\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7324 - mse: 0.0374 - accuracy: 0.7230\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7806 - mse: 0.0380 - accuracy: 0.7140\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7944 - mse: 0.0394 - accuracy: 0.6850\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7435 - mse: 0.0377 - accuracy: 0.7260\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7416 - mse: 0.0366 - accuracy: 0.7160\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7392 - mse: 0.0377 - accuracy: 0.7220\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7582 - mse: 0.0384 - accuracy: 0.7050\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7506 - mse: 0.0380 - accuracy: 0.7180\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7266 - mse: 0.0375 - accuracy: 0.7070\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7075 - mse: 0.0361 - accuracy: 0.7280\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7232 - mse: 0.0374 - accuracy: 0.7190\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7183 - mse: 0.0368 - accuracy: 0.7290\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7055 - mse: 0.0367 - accuracy: 0.7220\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7349 - mse: 0.0379 - accuracy: 0.7050\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7068 - mse: 0.0363 - accuracy: 0.7310\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7060 - mse: 0.0370 - accuracy: 0.7090\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6975 - mse: 0.0351 - accuracy: 0.7400\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6699 - mse: 0.0346 - accuracy: 0.7420\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7129 - mse: 0.0362 - accuracy: 0.7210\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6481 - mse: 0.0327 - accuracy: 0.7510\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6861 - mse: 0.0351 - accuracy: 0.7430\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7058 - mse: 0.0356 - accuracy: 0.7350\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6665 - mse: 0.0335 - accuracy: 0.7530\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6436 - mse: 0.0334 - accuracy: 0.7480\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6746 - mse: 0.0349 - accuracy: 0.7430\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6709 - mse: 0.0348 - accuracy: 0.7410\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6707 - mse: 0.0332 - accuracy: 0.7590\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6366 - mse: 0.0321 - accuracy: 0.7690\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6672 - mse: 0.0344 - accuracy: 0.7510\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6293 - mse: 0.0327 - accuracy: 0.7670\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6357 - mse: 0.0321 - accuracy: 0.7610\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6508 - mse: 0.0337 - accuracy: 0.7410\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6505 - mse: 0.0339 - accuracy: 0.7450\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6204 - mse: 0.0309 - accuracy: 0.7780\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6699 - mse: 0.0337 - accuracy: 0.7380\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6347 - mse: 0.0322 - accuracy: 0.7630\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6546 - mse: 0.0338 - accuracy: 0.7520\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6568 - mse: 0.0336 - accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7008 - mse: 0.0358 - accuracy: 0.7280\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6195 - mse: 0.0312 - accuracy: 0.7770\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6809 - mse: 0.0354 - accuracy: 0.7360\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6280 - mse: 0.0321 - accuracy: 0.7650\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6228 - mse: 0.0322 - accuracy: 0.7590\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6504 - mse: 0.0333 - accuracy: 0.7610\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6307 - mse: 0.0319 - accuracy: 0.7620\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6400 - mse: 0.0324 - accuracy: 0.7620\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5888 - mse: 0.0305 - accuracy: 0.7890\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5808 - mse: 0.0297 - accuracy: 0.7850\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6203 - mse: 0.0306 - accuracy: 0.7790\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6364 - mse: 0.0333 - accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5758 - mse: 0.0298 - accuracy: 0.7830\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6054 - mse: 0.0303 - accuracy: 0.7890\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6170 - mse: 0.0315 - accuracy: 0.7810\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6009 - mse: 0.0313 - accuracy: 0.7720\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5885 - mse: 0.0300 - accuracy: 0.7940\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6081 - mse: 0.0308 - accuracy: 0.7830\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5925 - mse: 0.0299 - accuracy: 0.7740\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6073 - mse: 0.0310 - accuracy: 0.7710\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6095 - mse: 0.0312 - accuracy: 0.7720\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6050 - mse: 0.0309 - accuracy: 0.7740\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5692 - mse: 0.0295 - accuracy: 0.7880\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5533 - mse: 0.0282 - accuracy: 0.8030\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5984 - mse: 0.0306 - accuracy: 0.7710\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6007 - mse: 0.0306 - accuracy: 0.7700\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6015 - mse: 0.0311 - accuracy: 0.7770\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6207 - mse: 0.0309 - accuracy: 0.7690\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6155 - mse: 0.0307 - accuracy: 0.7800\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5262 - mse: 0.0272 - accuracy: 0.8170\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6136 - mse: 0.0312 - accuracy: 0.7750\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5842 - mse: 0.0304 - accuracy: 0.7570\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5722 - mse: 0.0300 - accuracy: 0.7700\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5552 - mse: 0.0289 - accuracy: 0.7820\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5827 - mse: 0.0301 - accuracy: 0.7750\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5613 - mse: 0.0290 - accuracy: 0.7890\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5957 - mse: 0.0305 - accuracy: 0.7860\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5701 - mse: 0.0288 - accuracy: 0.7870\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5395 - mse: 0.0276 - accuracy: 0.8010\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5378 - mse: 0.0281 - accuracy: 0.7940\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5429 - mse: 0.0276 - accuracy: 0.8040\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5847 - mse: 0.0298 - accuracy: 0.7790\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4952 - mse: 0.0260 - accuracy: 0.8170\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5850 - mse: 0.0302 - accuracy: 0.7700\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5635 - mse: 0.0282 - accuracy: 0.7860\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5474 - mse: 0.0285 - accuracy: 0.8010\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5852 - mse: 0.0306 - accuracy: 0.7820\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5568 - mse: 0.0289 - accuracy: 0.7880\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5543 - mse: 0.0288 - accuracy: 0.7930\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5332 - mse: 0.0280 - accuracy: 0.7930\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5181 - mse: 0.0262 - accuracy: 0.8230\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5417 - mse: 0.0279 - accuracy: 0.8060\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5517 - mse: 0.0282 - accuracy: 0.7950\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5027 - mse: 0.0265 - accuracy: 0.8100\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5977 - mse: 0.0310 - accuracy: 0.7540\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5267 - mse: 0.0266 - accuracy: 0.7980\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5397 - mse: 0.0285 - accuracy: 0.7960\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5175 - mse: 0.0266 - accuracy: 0.7970\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5499 - mse: 0.0280 - accuracy: 0.7990\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5239 - mse: 0.0273 - accuracy: 0.8040\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5087 - mse: 0.0266 - accuracy: 0.8160\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5184 - mse: 0.0279 - accuracy: 0.7890\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5394 - mse: 0.0272 - accuracy: 0.7950\n"
     ]
    }
   ],
   "source": [
    "#Train models\n",
    "for model in model_list:\n",
    "    model.train_model(x=TRAIN_X,y=TRAIN_Y, epochs=100, batch=100, callbacks=[early_stopping_callback, tensorboard_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fb0bd0e",
   "metadata": {},
   "source": [
    "#### 4 Test Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "405ff2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2015 - mse: 0.0085 - accuracy: 0.9550\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2477 - mse: 0.0089 - accuracy: 0.9420\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4166 - mse: 0.0165 - accuracy: 0.9030\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2985 - mse: 0.0111 - accuracy: 0.9310\n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    model.test_model(x=TEST_X, y=TEST_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ba300c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: Loss = [0.20149695873260498, 0.008463161066174507, 0.9549999833106995]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 13, 6)         60        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 7, 6, 6)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 3, 2, 16)          2416      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 1, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 1, 16)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,646\n",
      "Trainable params: 2,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model 2: Loss = [0.2477436661720276, 0.00888358149677515, 0.9419999718666077]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 14, 13, 6)         60        \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 6, 6)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 2, 16)          2416      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 1, 16)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                340       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,026\n",
      "Trainable params: 3,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model 3: Loss = [0.2984861731529236, 0.011127294041216373, 0.9309999942779541]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 14, 13, 6)         60        \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 7, 6, 6)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 3, 2, 16)          2416      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 1, 1, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 1, 16)          0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20)                340       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,446\n",
      "Trainable params: 3,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model 4: Loss = [0.416596919298172, 0.016515502706170082, 0.902999997138977]\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 14, 13, 6)         60        \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 6, 6)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 3, 2, 16)          2416      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 1, 1, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, 1, 16)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                220       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,076\n",
      "Trainable params: 3,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sorted_architectures = sorted(model_list, key=lambda x: x.evaluation)\n",
    "\n",
    "# Print the loss of the top 5 models\n",
    "for i, architecture in enumerate(sorted_architectures):\n",
    "    print(f\"Model {i+1}: Loss = {architecture.evaluation}\")\n",
    "    architecture.print_architecture()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
